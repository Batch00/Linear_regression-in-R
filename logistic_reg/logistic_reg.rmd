
---
title: "STAT340 HW10: Prediction III, logistic regression"
author: "Carson Batchelor"
date: "November 2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

***

TODO: If you worked with any other students on this homework, please list their names and NetIDs here.

***

## Instructions

Update the "author" and "date" fields in the header and
complete the exercises below.
Knit the document, and submit **both the HTML and RMD** files to Canvas.

__Due date:__ December 1, 2022 at 11:59pm.

---

This homework will review our discussion of logistic regression from this week's lectures.

## 1) Interpreting logistic regression

Suppose we collect data for a group of students in a statistics class with independent variables $X_{1}=\text{hours studied}$, $X_{2}=\text{GPA}$, and binary response variable
$$
Y= \begin{cases} 1 &\mbox{ if student received an A} \\
  0 &\mbox{ otherwise. }
  \end{cases}
$$
Suppose that we fit a logistic regression model to the data, predicting $Y$ from $X_1$ and $X_2$ (and an intercept term) and produce estimated coefficients $\hat{\beta}_{0}=-6, \hat{\beta}_{1}=0.05, \hat{\beta}_{2}=1$.

### Part a) Logistic regression and probability

According to our fitted model, what is the probability that a student receives an A if they study for $40$ hours and have a GPA of $3.5$?

probability is .378

```{r}
b0 = -6
b1 = .05
b2 = 1

lr = -6 + 40*b1 + 3.5*b2

1/(1+exp(-lr))

```

### Part b) Interpreting coefficients
According to our fitted model, an additional hour spent studying is associated with *how much* of an increase in the log odds of receiving an A?

each hour is associated with about a .012 increase in odds

```{r}

lr1 = -6 + 40*b1 + 3.5*b2
lr2 = -6 + 41*b1 + 3.5*b2

first = 1/(1+exp(-lr1))
second = 1/(1+exp(-lr2))

second-first

```

### Part c) "Inverting" logistic regression probabilities
According to our fitted model, how many hours would the student in Part (a) need to study to have a $50\%$ chance of getting an A in the class?
That is, keeping GPA fixed at $3.5$, how many hours of study are needed so that the probability of an A is $50\%$?
If you aren't up for the math, feel free to find an approximate solution via guess-and-check in R.

***

about 50 hours of studying would be needed for the probability of an A to be 50%

***

```{r}

lr = -6 + 50*b1 + 3.5*b2

1/(1+exp(-lr))

```

## 2) `mtcars` once again

Let's take yet another look at the `mtcars` data set.
Recall that the columns of this data set are:
```{r}
names(mtcars)
```

The `am` column encodes whether a car is automatic (`0`) or manual (`1`).
Let's build a model to predict whether a car is manual or automatic.

### Part a) Fitting a model

Fit a logistic regression model to regress `am` against the `drat` and `disp` (and an intercept term).

```{r}

cars_log <- glm( am ~ 1 + drat + disp, data=mtcars, family=binomial );
summary(cars_log)

```

### Part b) Interpreting estimates

Which coefficients (if any) are statistically significantly different from zero at the $\alpha=0.05$ level?
Interpret the meaning of the estimated coefficient(s) that is/are statistically significantly different from zero.

***

drat is statistically significant at an alpha level of .05.

The coeficient reflects an estimate that an increase of one unit in `drat` is associated with an increase of about $4.88$ in the *log-odds* of the cars transmission.

***

### Part c) paring down the model

Choose one of the statistically significant predictors above and re-fit a model using *only* that variable (and an intercept) to predict `am`.
We'll see how to compare the quality of this model to the one from Part (a) when we talk about cross-validation (CV) in upcoming lectures.
For now, compare the estimated coefficient of this variable in both models.
Is there a sizable difference?

Does anything else notable change about the model?

the estimated coefficient of "drat" is a little bit higher (about .7) but now is statistically significant at an alpha level of .01 which is a sizable difference.

The intercept coefficient is also now statistically significant at an alpha level of .01

```{r}

cars_log <- glm( am ~ 1 + drat, data=mtcars, family=binomial );
summary(cars_log)

```

### Part d) Plotting your findings

Choose one of the statistically significant predictors above.
Use `ggplot2` to plot `am` as a function of this predictor, and overlay a curve describing the logistic regression output when using *only* this predictor to predict `am` (i.e., the model from Part c above).

```{r}
library(tidyverse)
ggplot( mtcars, aes(x=drat, y=am) ) + 
  geom_point() +
  geom_smooth(formula='y ~ 1+x', se=FALSE,
                       method='glm',
                       method.args=list(family = "binomial"))
              
```