
---
title: "STAT340 HW09: Prediction II, multiple regression"
author: "TODO:Carson Batchelor"
date: "November 2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

***

TODO: If you worked with any other students on this homework, please list their names and NetIDs here.

***

## Instructions

Update the "author" and "date" fields in the header and
complete the exercises below.
Knit the document, and submit **both the HTML and RMD** files to Canvas.

__Due date:__ November 17, 2022 at 11:59pm.

---

This homework will review our discussion of multiple regression from this week's lectures.

## 1) More regression with `mtcars`

In lecture, we worked briefly with the `mtcars` data set.
Let's get more regression practice by working with it some more.

### a) background

Run `?mtcars` in the console (please __do not__ add it to this `Rmd` file) and briefly read the help page.
Specifically, take note of the following:

1. What is the source of this data?
2. What is this data set measuring (i.e., what was the response variable in the original study, at least based on the brief description in the R documentation)?
3. What predictors are available and what do they mean?

***

1. Henderson and Velleman (1981), Building multiple regression models interactively. Biometrics, 37, 391â€“411.

2. noncrucial coding of the Mazda's rotary engine as a straight six-cylinder engine and the Porsche's flat engine as a V engine, as well as the inclusion of the diesel Mercedes 240D

3. 
[, 1]	mpg	- Miles/(US) gallon
[, 2]	cyl	- Number of cylinders
[, 3]	disp	- Displacement (cu.in.)
[, 4]	hp	- Gross horsepower
[, 5]	drat	- Rear axle ratio
[, 6]	wt	- Weight (1000 lbs)
[, 7]	qsec	- 1/4 mile time
[, 8]	vs	- Engine (0 = V-shaped, 1 = straight)
[, 9]	am	- Transmission (0 = automatic, 1 = manual)
[,10]	gear	- Number of forward gears
[,11]	carb	- Number of carburetors

***

You may want to also run `head(mtcars, 10)` or `View(mtcars)` to inspect the data frame briefly before moving on.

### b) Fitting a model

Use `lm` to run a regression of `mpg` on a few predictors in the data frame (choose two or three that you think would make a good model-- don't use all ten; we'll talk about why in later lectures).
Make sure to include `data = mtcars` as a keyword argument to `lm` so that R knows what data frame to use.

```{r}
lm.mtcars = lm(mpg ~ 1 + wt + hp, data = mtcars)

plot(lm.mtcars,ask=F,which=1:2)
```

Briefly inspect the residuals plot by running `plot(lm.mtcars,ask=F,which=1:2)`.
What do you observe, and what does it mean?

***

It seems that the residuals are all fairly close to the Q-Q line which means that the residuals are close enough to it to be well-described by a normal

***

### c) Interpreting the model

View the summary of your model by uncommenting and running the code below.
```{r}
summary(lm.mtcars)
```

Pick one of your predictors and give an interpretation of the estimate and standard error for its coefficient.
Be careful in your wording of the interpretation.

***
It appears that weight (wt) is associated with changes in mpg. with an estimate of -3.878 and std error of .633 and a p value of 1.12e-.06.

***

Which coefficients are statistically significantly different from zero? How do you know?

***

We see that our intercept term and the coefficients for horsepower (hp) and weight (wt) are flagged as being significant with wt having a p-value that shows significance at alpha = .001 and hp having a p-value that shows significance at alpha = .01.

***

### d) Interpreting residuals

What is the Residual Standard Error (RSE) for this model? How many degrees of freedom does it have?

***

Residual standard error: 2.593 on 29 degrees of freedom

***

What is the value of $R^2$ for this model? (__Hint:__ look at the output of `summary`) Give an interpretation of this value.

***

Multiple R-squared:  0.8268 --> Since $R^2$ is fairly close to 1, we can be fairly confident that our linear model is accurately capturing the structure in the data.

$R^2$ is measuring the proportion (between 0 and 1) of the variation in the responses (TSS) that is explained by our model. 

***

### e) Adjusted $R^2$

Briefly read about the adjusted $R^2$ [here](https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/adjusted-r2/).
What is the adjusted $R^2$ of this model and how does this differ from the usual $R^2$ value? (__Hint:__ again, look at the output of `summary`).

***

Adjusted R-squared:  0.8148 --> This is very close to the usual R^2 value and differs by about .012.

***

### f) CIs for coefficients

Read the documentation for the `confint` function, and use it to generate $95\%$ confidence intervals for the coefficients of your model.
Give an interpretation of these confidence intervals.

```{r}
confint(lm.mtcars, level = .95)
```

***

This Computes confidence intervals for all the parameters in my lm fitted model. It makes a 95 & confidence interval for the intercept, wt coefficient and the hp coefficient. These show the interval where the coefficient will be within 95% of the time 

***

## 2) the `cats` data set

The `cats` data set, included in the `MASS` library, contains data recorded from 144 cats.
Each row of the data set contains the body weight (`Bwt`, in kgs), heart weight (`Hwt`, in grams) and the sex (`Sex`, levels `'F'` and `'M'`) for one of the cats in the data set.

__Part a: plotting the data__

Create a scatter plot showing heart weight on the y-axis and body weight on the x-axis.
Ignore the `Sex` variable in this plot.

```{r}
library(tidyverse)
library(MASS)
head(cats)
```

```{r}

ggplot(cats, aes(x=Bwt, y=Hwt)) +
  geom_point()

```

Briefly describe what you see. Is there a clear trend in the data?

It seems like there is a clear linear trend of as the Bwt increases the Hwt increases as well on average. 

__Part b: fitting a linear model__

Fit a linear regression model to predict cat heart weight from cat body weight (and using an intercept term, of course).

```{r}

cats_lm = lm(Hwt ~ 1 + Bwt, data = cats)
summary(cats_lm)

```

Examine the coefficients of your fitted model.
What is the coefficient for the `Bwt` variable?
Interpret this coefficient-- a unit change in body weight yields how much change in heart weight?

***

The coefficient for Bwt is 4.0341 - This means that a unit change in body weight is associated with about 4.0341 change in heart weight

***

__Part c: back to plotting__

Create the same plot from Part a above, but this time color the points in the scatter plot according to the `Sex` variable.
You may use either `ggplot2` or the built-in R plotting tools, though I would recommend the former, for this.

You should see a clear pattern. Describe it. A sentence or two is fine here.

```{r}

ggplot(cats, aes(x=Bwt, y=Hwt, color = Sex)) +
  geom_point() +
  geom_smooth(method='lm', formula='y~1+x', se=FALSE )


```

***

I still see a linear relationship where higher Bwt is associated with a higher Hwt but it seems that female cats tend to have a lower Bwt and therefore a lower Hwt on average but there is less evidence for a linear relationship.

***

__Part d: adding `Sex` and an interaction__

From looking at the data, it should be clear that the `Sex` variable has explanatory power in predicting heart weight, but it is also very correlated with body weight.

Fit a new linear regression model, still predicting heart weight, but this time including both body weight and sex as predictors *and* an interaction term between body weight and sex.
Take note of how R assigns `Sex` a dummy encoding.

```{r}

cats_inter <- lm( Hwt ~ 1 + Bwt + Sex + Bwt:Sex, data=cats);
summary(cats_inter)

```

Examine the outputs of your model.
In particular, note the coefficients of `Sex` and the interaction between `Bwt` and `Sex`.
Are both of these coefficients statistically significantly different from zero?
How do you interpret the interaction term?

***

Yes both of these values are statistically significant and an alpha level of .05. The interaction term is taking each sex and seeing the interaction of Bwt for that sex so it is more resonable.

***

